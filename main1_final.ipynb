{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a5a7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "BantAI TravelAware - Advanced Fraud Detection System\n",
    "====================================================\n",
    "\n",
    "A comprehensive fraud detection system that combines:\n",
    "- Geographic travel analysis with impossible travel detection\n",
    "- Machine learning behavioral pattern recognition\n",
    "- Technical indicators analysis\n",
    "- Unified risk scoring system\n",
    "\n",
    "Author: BantAI Team\n",
    "Version: 1.0\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score, precision_recall_curve, f1_score\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Optional libraries\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    IMB_AVAILABLE = True\n",
    "except Exception:\n",
    "    IMB_AVAILABLE = False\n",
    "\n",
    "# tqdm fallback\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except Exception:\n",
    "    tqdm = lambda iterable, **kwargs: iterable\n",
    "\n",
    "# plotting libs (optional display)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "class BantAI_TravelAware:\n",
    "    def __init__(self,\n",
    "                 cache_file=\"geocache.json\",\n",
    "                 geocode_delay=1.0,\n",
    "                 ml_model_path=\"bantai_model.pkl\",\n",
    "                 ml_model_feature_columns=None):\n",
    "        \"\"\"\n",
    "        cache_file: path to JSON cache for geocoding\n",
    "        geocode_delay: seconds between geocode requests (respect Nominatim policies)\n",
    "        ml_model_path: where to save the trained ML model\n",
    "        ml_model_feature_columns: optional list of what ML features to expect (auto-filled)\n",
    "        \"\"\"\n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "        self.geolocator = Nominatim(user_agent=\"bantai_ai\")\n",
    "        self.cache_file = cache_file\n",
    "        self.geo_cache = self._load_cache()\n",
    "        self.geocode_delay = geocode_delay\n",
    "        self.ml_model_path = ml_model_path\n",
    "        self.ml_feature_columns = ml_model_feature_columns\n",
    "\n",
    "    # ------------------------\n",
    "    # Cache handling\n",
    "    # ------------------------\n",
    "    def _load_cache(self):\n",
    "        if os.path.exists(self.cache_file):\n",
    "            try:\n",
    "                with open(self.cache_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                    return json.load(f)\n",
    "            except Exception:\n",
    "                return {}\n",
    "        return {}\n",
    "\n",
    "    def _save_cache(self):\n",
    "        with open(self.cache_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(self.geo_cache, f)\n",
    "\n",
    "    # ------------------------\n",
    "    # Geocoding with cache + rate limit\n",
    "    # ------------------------\n",
    "    def get_coordinates(self, city, country):\n",
    "        \"\"\"Return (lat, lon) or None. Skips invalid inputs.\"\"\"\n",
    "        if pd.isna(city) or pd.isna(country):\n",
    "            return None\n",
    "        if str(city).strip() == \"-\" or str(country).strip() == \"-\":\n",
    "            return None\n",
    "\n",
    "        key = f\"{city.strip()},{country.strip()}\"\n",
    "        if key in self.geo_cache:\n",
    "            val = self.geo_cache[key]\n",
    "            return tuple(val) if val is not None else None\n",
    "\n",
    "        # Not in cache -> geocode\n",
    "        try:\n",
    "            location = self.geolocator.geocode(key, timeout=10)\n",
    "            time.sleep(self.geocode_delay)  # rate limit\n",
    "            if location:\n",
    "                coords = (location.latitude, location.longitude)\n",
    "                self.geo_cache[key] = coords\n",
    "                self._save_cache()\n",
    "                return coords\n",
    "        except Exception as e:\n",
    "            # store None to avoid repeated attempts\n",
    "            print(f\"‚ö†Ô∏è Geocoding error for {key}: {e}\")\n",
    "        self.geo_cache[key] = None\n",
    "        self._save_cache()\n",
    "        return None\n",
    "\n",
    "    def precompute_all_coords(self, df):\n",
    "        \"\"\"Precompute coordinates for all unique (city,country) pairs in df.\"\"\"\n",
    "        if not {\"city\", \"country\"}.issubset(set(df.columns)):\n",
    "            return\n",
    "        unique_locations = df[[\"city\", \"country\"]].drop_duplicates()\n",
    "        print(f\"üîç Precomputing coordinates for {len(unique_locations)} unique city-country pairs...\")\n",
    "        for _, row in tqdm(unique_locations.iterrows(), total=len(unique_locations)):\n",
    "            self.get_coordinates(row[\"city\"], row[\"country\"])\n",
    "        print(\"‚úÖ All coordinates cached!\")\n",
    "\n",
    "    # ------------------------\n",
    "    # Travel & distance helpers\n",
    "    # ------------------------\n",
    "    def compute_distance_km(self, city1, country1, city2, country2):\n",
    "        c1 = self.get_coordinates(city1, country1)\n",
    "        c2 = self.get_coordinates(city2, country2)\n",
    "        if c1 and c2:\n",
    "            try:\n",
    "                return geodesic(c1, c2).kilometers\n",
    "            except Exception:\n",
    "                return 0.0\n",
    "        return 0.0\n",
    "\n",
    "    def travel_plausibility(self, last_time, last_city, last_country, curr_time, curr_city, curr_country):\n",
    "        \"\"\"\n",
    "        Returns dict with distance_km, time_gap_hours, travel_speed_kmh, plausible(bool), travel_risk (0-1)\n",
    "        \"\"\"\n",
    "        distance_km = self.compute_distance_km(last_city, last_country, curr_city, curr_country)\n",
    "        time_gap_hours = (curr_time - last_time).total_seconds() / 3600.0 if curr_time and last_time else np.inf\n",
    "\n",
    "        max_speed = 900.0  # km/h for commercial aircraft\n",
    "        min_travel_time = distance_km / max_speed if max_speed > 0 else np.inf\n",
    "        buffer = 4.0  # hours for airport/layovers\n",
    "        required = min_travel_time + buffer\n",
    "\n",
    "        if distance_km == 0:\n",
    "            plausible = True\n",
    "            travel_risk = 0.0\n",
    "        elif time_gap_hours >= required:\n",
    "            plausible = True\n",
    "            travel_risk = 0.0\n",
    "        else:\n",
    "            plausible = False\n",
    "            # risk modifier proportional to how impossible\n",
    "            ratio = (required - time_gap_hours) / (required + 1e-6)\n",
    "            travel_risk = min(1.0, 0.6 + 0.4 * ratio)  # base high risk for impossible travel\n",
    "\n",
    "        return {\n",
    "            \"distance_km\": distance_km,\n",
    "            \"time_gap_hours\": time_gap_hours,\n",
    "            \"travel_speed_kmh\": (distance_km / time_gap_hours) if time_gap_hours > 0 else 0.0,\n",
    "            \"plausible\": plausible,\n",
    "            \"travel_risk\": travel_risk,\n",
    "            \"required_hours\": required\n",
    "        }\n",
    "\n",
    "    # ------------------------\n",
    "    # Behavioral consistency\n",
    "    # ------------------------\n",
    "    def behavioral_consistency_score(self, user_history_df, current_row):\n",
    "        \"\"\"\n",
    "        user_history_df: DataFrame of previous logins for the same user (sorted by time)\n",
    "        current_row: a dict/Series for current login\n",
    "        Returns score in [0,1] where 1 = fully consistent.\n",
    "        \"\"\"\n",
    "        # Default score\n",
    "        score = 1.0\n",
    "        factors = []\n",
    "\n",
    "        # Device consistency\n",
    "        prev_devices = user_history_df[\"Device Type\"].dropna().unique().tolist() if \"Device Type\" in user_history_df else []\n",
    "        curr_device = current_row.get(\"Device Type\", None)\n",
    "        if curr_device in prev_devices:\n",
    "            factors.append(\"Known device\")\n",
    "        else:\n",
    "            score -= 0.25\n",
    "            factors.append(\"New device\")\n",
    "\n",
    "        # Time-of-day consistency\n",
    "        if \"Login Timestamp\" in user_history_df:\n",
    "            hist_hours = pd.to_datetime(user_history_df[\"Login Timestamp\"]).dt.hour.dropna().tolist()\n",
    "            if len(hist_hours) > 0:\n",
    "                curr_hour = pd.to_datetime(current_row[\"Login Timestamp\"]).hour\n",
    "                avg = np.mean(hist_hours)\n",
    "                if abs(curr_hour - avg) <= 3:\n",
    "                    factors.append(\"Time consistent\")\n",
    "                else:\n",
    "                    score -= 0.15\n",
    "                    factors.append(\"Unusual hour\")\n",
    "        else:\n",
    "            factors.append(\"No time history\")\n",
    "\n",
    "        # Location familiarity\n",
    "        prev_countries = user_history_df[\"Country\"].dropna().unique().tolist() if \"Country\" in user_history_df else []\n",
    "        if current_row.get(\"Country\") in prev_countries:\n",
    "            factors.append(\"Known country\")\n",
    "            score += 0.05\n",
    "        else:\n",
    "            factors.append(\"New country\")\n",
    "\n",
    "        # Device/browser fingerprint approximation (based on UA string change)\n",
    "        prev_ua = user_history_df[\"User Agent String\"].dropna().astype(str).unique().tolist() if \"User Agent String\" in user_history_df else []\n",
    "        curr_ua = str(current_row.get(\"User Agent String\", \"\"))\n",
    "        if any(curr_ua == ua for ua in prev_ua):\n",
    "            factors.append(\"Same UA\")\n",
    "        else:\n",
    "            score -= 0.1\n",
    "            factors.append(\"UA changed\")\n",
    "\n",
    "        # Clamp\n",
    "        score = max(0.0, min(1.0, score))\n",
    "        return {\"consistency_score\": score, \"factors\": factors}\n",
    "\n",
    "    # ------------------------\n",
    "    # Technical indicator scoring\n",
    "    # ------------------------\n",
    "    def technical_score(self, row):\n",
    "        \"\"\"\n",
    "        Build technical risk score in [0,1] based on available indicators.\n",
    "        Use Round-Trip Time (ms) as high_latency, Is Attack IP, Login Successful.\n",
    "        \"\"\"\n",
    "        score = 0.0\n",
    "        factors = []\n",
    "\n",
    "        # Attack IP\n",
    "        attack_ip = False\n",
    "        if \"Is Attack IP\" in row:\n",
    "            val = row[\"Is Attack IP\"]\n",
    "            # Support both boolean and strings\n",
    "            if isinstance(val, str):\n",
    "                attack_ip = val.strip().upper() in [\"TRUE\", \"1\", \"YES\"]\n",
    "            else:\n",
    "                attack_ip = bool(val)\n",
    "        if attack_ip:\n",
    "            score += 0.6\n",
    "            factors.append(\"Known attack IP\")\n",
    "\n",
    "        # High latency\n",
    "        if \"Round-Trip Time [ms]\" in row:\n",
    "            try:\n",
    "                rtt = float(row[\"Round-Trip Time [ms]\"])\n",
    "                if rtt > 500:  # threshold for suspiciously high latency\n",
    "                    score += 0.25\n",
    "                    factors.append(\"High RTT\")\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # Failed login\n",
    "        if \"Login Successful\" in row:\n",
    "            ok = row[\"Login Successful\"]\n",
    "            # handle string forms\n",
    "            if isinstance(ok, str):\n",
    "                success = ok.strip().upper() in [\"TRUE\", \"1\", \"YES\"]\n",
    "            else:\n",
    "                success = bool(ok)\n",
    "            if not success:\n",
    "                score += 0.35\n",
    "                factors.append(\"Failed login\")\n",
    "\n",
    "        # normalize to [0,1]\n",
    "        score = min(1.0, score)\n",
    "        return {\"technical_score\": score, \"factors\": factors}\n",
    "\n",
    "    # ------------------------\n",
    "    # Feature engineering for ML\n",
    "    # ------------------------\n",
    "    def build_ml_features_for_df(self, df):\n",
    "        \"\"\"\n",
    "        Build ML feature matrix from chronological df.\n",
    "        Expects df to contain: time (parsed), Country, City, Device Type, Round-Trip Time [ms], Is Attack IP, Login Successful, User Agent String, ASN\n",
    "        Returns X (DataFrame), y (Series)\n",
    "        Each sample corresponds to a login event with features computed w.r.t. previous event of same user.\n",
    "        \"\"\"\n",
    "        rows = []\n",
    "        labels = []\n",
    "        groupby_user = \"User ID\" if \"User ID\" in df.columns else None\n",
    "\n",
    "        if groupby_user:\n",
    "            for user, group in df.groupby(groupby_user):\n",
    "                group = group.sort_values(\"time\")\n",
    "                if len(group) < 2:\n",
    "                    continue\n",
    "                prev = None\n",
    "                for idx, row in group.iterrows():\n",
    "                    if prev is None:\n",
    "                        prev = row\n",
    "                        continue\n",
    "                    curr = row\n",
    "                    # Features: travel-based\n",
    "                    dist = self.compute_distance_km(prev.get(\"City\"), prev.get(\"Country\"), curr.get(\"City\"), curr.get(\"Country\"))\n",
    "                    time_gap = (pd.to_datetime(curr[\"time\"]) - pd.to_datetime(prev[\"time\"])).total_seconds() / 3600.0\n",
    "                    travel_speed = dist / time_gap if time_gap > 0 else 0.0\n",
    "                    impossible_flag = 1 if (not self.travel_plausibility(pd.to_datetime(prev[\"time\"]), prev.get(\"City\"), prev.get(\"Country\"), pd.to_datetime(curr[\"time\"]), curr.get(\"City\"), curr.get(\"Country\"))[\"plausible\"]) else 0\n",
    "\n",
    "                    # Temporal features\n",
    "                    hour = pd.to_datetime(curr[\"time\"]).hour\n",
    "                    night_access = 1 if (hour >= 22 or hour <= 5) else 0\n",
    "                    business_hours = 1 if (8 <= hour <= 17) else 0\n",
    "                    hour_norm = hour / 23.0\n",
    "                    day_norm = pd.to_datetime(curr[\"time\"]).weekday() / 6.0\n",
    "\n",
    "                    # Device features\n",
    "                    mobile_device = 1 if isinstance(curr.get(\"Device Type\", \"\"), str) and \"mobile\" in curr.get(\"Device Type\", \"\").lower() else 0\n",
    "                    device_change = 1 if prev.get(\"Device Type\") != curr.get(\"Device Type\") else 0\n",
    "\n",
    "                    # Technical features\n",
    "                    attack_ip = 1 if str(curr.get(\"Is Attack IP\", False)).strip().upper() in [\"TRUE\", \"1\", \"YES\"] else 0\n",
    "                    try:\n",
    "                        rtt = float(curr.get(\"Round-Trip Time [ms]\") if curr.get(\"Round-Trip Time [ms]\") is not None else 0.0)\n",
    "                    except Exception:\n",
    "                        rtt = 0.0\n",
    "                    high_latency = 1 if rtt > 500 else 0\n",
    "                    failed_login = 0\n",
    "                    if \"Login Successful\" in curr:\n",
    "                        v = curr[\"Login Successful\"]\n",
    "                        if isinstance(v, str):\n",
    "                            failed_login = 0 if v.strip().upper() in [\"TRUE\", \"1\", \"YES\"] else 1\n",
    "                        else:\n",
    "                            failed_login = 0 if bool(v) else 1\n",
    "\n",
    "                    # ASN change (proxy suspicion)\n",
    "                    asn_change = 1 if prev.get(\"ASN\") != curr.get(\"ASN\") else 0\n",
    "\n",
    "                    # Foreign access\n",
    "                    foreign_access = 0 if str(curr.get(\"Country\", \"\")).strip().upper() in [\"PH\", \"PHL\", \"PHILIPPINES\"] else 1\n",
    "\n",
    "                    # Simple metro_manila flag\n",
    "                    metro_manila = 1 if str(curr.get(\"City\", \"\")).strip().lower() in [\"manila\", \"quezon city\", \"makati\", \"taguig\", \"pasig\"] else 0\n",
    "\n",
    "                    features = {\n",
    "                        \"distance_km\": dist,\n",
    "                        \"time_gap_hours\": time_gap,\n",
    "                        \"travel_speed_kmh\": travel_speed,\n",
    "                        \"impossible_travel\": impossible_flag,\n",
    "                        \"night_access\": night_access,\n",
    "                        \"business_hours\": business_hours,\n",
    "                        \"hour_norm\": hour_norm,\n",
    "                        \"day_norm\": day_norm,\n",
    "                        \"mobile_device\": mobile_device,\n",
    "                        \"device_change\": device_change,\n",
    "                        \"attack_ip\": attack_ip,\n",
    "                        \"high_latency\": high_latency,\n",
    "                        \"failed_login\": failed_login,\n",
    "                        \"asn_change\": asn_change,\n",
    "                        \"foreign_access\": foreign_access,\n",
    "                        \"metro_manila\": metro_manila,\n",
    "                        \"rtt_ms\": rtt\n",
    "                    }\n",
    "\n",
    "                    rows.append(features)\n",
    "                    labels.append(1 if str(curr.get(\"label\", False)).strip().upper() in [\"TRUE\", \"1\", \"YES\"] else 0)\n",
    "                    prev = curr\n",
    "        else:\n",
    "            # If no user id, fallback to consecutive global rows (less ideal)\n",
    "            df = df.sort_values(\"time\")\n",
    "            prev = None\n",
    "            for idx, curr in df.iterrows():\n",
    "                if prev is None:\n",
    "                    prev = curr\n",
    "                    continue\n",
    "                dist = self.compute_distance_km(prev.get(\"City\"), prev.get(\"Country\"), curr.get(\"City\"), curr.get(\"Country\"))\n",
    "                time_gap = (pd.to_datetime(curr[\"time\"]) - pd.to_datetime(prev[\"time\"])).total_seconds() / 3600.0\n",
    "                travel_speed = dist / time_gap if time_gap > 0 else 0.0\n",
    "                impossible_flag = 1 if (not self.travel_plausibility(pd.to_datetime(prev[\"time\"]), prev.get(\"City\"), prev.get(\"Country\"), pd.to_datetime(curr[\"time\"]), curr.get(\"City\"), curr.get(\"Country\"))[\"plausible\"]) else 0\n",
    "                hour = pd.to_datetime(curr[\"time\"]).hour\n",
    "                night_access = 1 if (hour >= 22 or hour <= 5) else 0\n",
    "                business_hours = 1 if (8 <= hour <= 17) else 0\n",
    "                hour_norm = hour / 23.0\n",
    "                day_norm = pd.to_datetime(curr[\"time\"]).weekday() / 6.0\n",
    "                mobile_device = 1 if isinstance(curr.get(\"Device Type\", \"\"), str) and \"mobile\" in curr.get(\"Device Type\", \"\").lower() else 0\n",
    "                device_change = 1 if prev.get(\"Device Type\") != curr.get(\"Device Type\") else 0\n",
    "                attack_ip = 1 if str(curr.get(\"Is Attack IP\", False)).strip().upper() in [\"TRUE\", \"1\", \"YES\"] else 0\n",
    "                try:\n",
    "                    rtt_val = curr.get(\"Round-Trip Time [ms]\", 0.0)\n",
    "                    rtt = float(rtt_val) if rtt_val is not None else 0.0\n",
    "                except Exception:\n",
    "                    rtt = 0.0\n",
    "                high_latency = 1 if rtt > 500 else 0\n",
    "                failed_login = 0\n",
    "                if \"Login Successful\" in curr:\n",
    "                    v = curr[\"Login Successful\"]\n",
    "                    if isinstance(v, str):\n",
    "                        failed_login = 0 if v.strip().upper() in [\"TRUE\", \"1\", \"YES\"] else 1\n",
    "                    else:\n",
    "                        failed_login = 0 if bool(v) else 1\n",
    "                asn_change = 1 if prev.get(\"ASN\") != curr.get(\"ASN\") else 0\n",
    "                foreign_access = 0 if str(curr.get(\"Country\", \"\")).strip().upper() in [\"PH\", \"PHL\", \"PHILIPPINES\"] else 1\n",
    "                metro_manila = 1 if str(curr.get(\"City\", \"\")).strip().lower() in [\"manila\", \"quezon city\", \"makati\", \"taguig\", \"pasig\"] else 0\n",
    "\n",
    "                features = {\n",
    "                    \"distance_km\": dist,\n",
    "                    \"time_gap_hours\": time_gap,\n",
    "                    \"travel_speed_kmh\": travel_speed,\n",
    "                    \"impossible_travel\": impossible_flag,\n",
    "                    \"night_access\": night_access,\n",
    "                    \"business_hours\": business_hours,\n",
    "                    \"hour_norm\": hour_norm,\n",
    "                    \"day_norm\": day_norm,\n",
    "                    \"mobile_device\": mobile_device,\n",
    "                    \"device_change\": device_change,\n",
    "                    \"attack_ip\": attack_ip,\n",
    "                    \"high_latency\": high_latency,\n",
    "                    \"failed_login\": failed_login,\n",
    "                    \"asn_change\": asn_change,\n",
    "                    \"foreign_access\": foreign_access,\n",
    "                    \"metro_manila\": metro_manila,\n",
    "                    \"rtt_ms\": rtt\n",
    "                }\n",
    "                rows.append(features)\n",
    "                labels.append(1 if str(curr.get(\"label\", False)).strip().upper() in [\"TRUE\", \"1\", \"YES\"] else 0)\n",
    "                prev = curr\n",
    "\n",
    "        X = pd.DataFrame(rows)\n",
    "        y = pd.Series(labels)\n",
    "        X = X.fillna(0)\n",
    "        return X, y\n",
    "\n",
    "    # ------------------------\n",
    "    # Enhanced Training / evaluation\n",
    "    # ------------------------\n",
    "    def train_model_from_csv(self,\n",
    "                             csv_path,\n",
    "                             nrows=20000,\n",
    "                             label_column=\"Is Attack IP\",\n",
    "                             use_smote=True,\n",
    "                             save_model=True,\n",
    "                             test_size=0.2,\n",
    "                             random_state=42,\n",
    "                             threshold=0.5):\n",
    "        \"\"\"\n",
    "        Enhanced training with threshold optimization and feature importance analysis.\n",
    "        \"\"\"\n",
    "        # 1) read\n",
    "        df = pd.read_csv(csv_path, nrows=nrows)\n",
    "\n",
    "        # 2) sanitize - replace '-' with None in Region/City\n",
    "        if \"Region\" in df.columns:\n",
    "            df[\"Region\"] = df[\"Region\"].replace(\"-\", None)\n",
    "        if \"City\" in df.columns:\n",
    "            df[\"City\"] = df[\"City\"].replace(\"-\", None)\n",
    "\n",
    "        # 3) map standard columns\n",
    "        df = df.rename(columns={\n",
    "            \"Login Timestamp\": \"time\",\n",
    "            \"Country\": \"Country\",\n",
    "            \"City\": \"City\",\n",
    "            label_column: \"label\"\n",
    "        })\n",
    "\n",
    "        # 4) parse times\n",
    "        df[\"time\"] = pd.to_datetime(df[\"time\"], errors=\"coerce\")\n",
    "        df = df.dropna(subset=[\"time\", \"Country\"])\n",
    "\n",
    "        print(f\"üìÇ Loaded {len(df)} rows. Preview:\")\n",
    "        print(df.head(3))\n",
    "\n",
    "        # 6) precompute coordinates\n",
    "        self.precompute_all_coords(df.rename(columns={\"Country\": \"country\", \"City\": \"city\"}).rename_axis(None))\n",
    "\n",
    "        # 7) create features & labels for ML\n",
    "        df_fe = df.copy()\n",
    "        if \"User ID\" not in df_fe.columns:\n",
    "            df_fe[\"User ID\"] = df_fe.get(\"User ID\", None)\n",
    "        \n",
    "        df_fe = df_fe.rename(columns={\n",
    "            \"time\": \"time\",\n",
    "            \"Country\": \"Country\",\n",
    "            \"City\": \"City\",\n",
    "            \"Device Type\": \"Device Type\",\n",
    "            \"Round-Trip Time [ms]\": \"Round-Trip Time [ms]\",\n",
    "            \"Is Attack IP\": \"Is Attack IP\",\n",
    "            \"Login Successful\": \"Login Successful\",\n",
    "            \"User Agent String\": \"User Agent String\",\n",
    "            \"ASN\": \"ASN\"\n",
    "        })\n",
    "\n",
    "        df_fe[\"time\"] = pd.to_datetime(df_fe[\"time\"], errors=\"coerce\")\n",
    "        X, y = self.build_ml_features_for_df(df_fe)\n",
    "\n",
    "        if X.shape[0] == 0:\n",
    "            print(\"‚ö†Ô∏è Not enough consecutive login pairs to build training examples.\")\n",
    "            return\n",
    "\n",
    "        print(\"‚öñÔ∏è Class distribution before train/test split:\")\n",
    "        print(y.value_counts())\n",
    "\n",
    "        # 9) split\n",
    "        try:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "        except Exception:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "        # 10) optional SMOTE\n",
    "        if use_smote and IMB_AVAILABLE:\n",
    "            print(\"‚ú® Applying SMOTE oversampling on training set...\")\n",
    "            sm = SMOTE(random_state=random_state)\n",
    "            X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "            print(\"Post-SMOTE class distribution:\", pd.Series(y_train).value_counts())\n",
    "\n",
    "        # 11) scale numeric features\n",
    "        self.scaler = StandardScaler()\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "\n",
    "        # 12) train\n",
    "        clf = RandomForestClassifier(n_estimators=200, random_state=random_state, class_weight=\"balanced\")\n",
    "        clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # 13) Enhanced evaluation with threshold optimization\n",
    "        y_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "        \n",
    "        # Find optimal threshold using F1-score\n",
    "        thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "        f1_scores = []\n",
    "        for thresh in thresholds:\n",
    "            y_pred_thresh = (y_proba >= thresh).astype(int)\n",
    "            f1_scores.append(f1_score(y_test, y_pred_thresh))\n",
    "        \n",
    "        optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "        print(f\"üéØ Optimal threshold based on F1-score: {optimal_threshold:.2f}\")\n",
    "        \n",
    "        # Use optimal threshold for final predictions\n",
    "        y_pred = (y_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "        print(\"üìä Model Performance (Optimal Threshold):\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(f\"AUC = {roc_auc_score(y_test, y_proba):.3f}\")\n",
    "        \n",
    "        # Feature importance analysis\n",
    "        if hasattr(clf, 'feature_importances_'):\n",
    "            feature_importance = pd.DataFrame({\n",
    "                'feature': X.columns,\n",
    "                'importance': clf.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            print(\"\\nüîç Top 10 Most Important Features:\")\n",
    "            print(feature_importance.head(10))\n",
    "            \n",
    "            # Plot feature importance\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.barh(feature_importance.head(10)['feature'][::-1], \n",
    "                    feature_importance.head(10)['importance'][::-1])\n",
    "            plt.title('Top 10 Feature Importance')\n",
    "            plt.xlabel('Importance')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # Enhanced visualization: three-panel layout\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        # ROC Curve subplot\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.plot(fpr, tpr, lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate (Recall)')\n",
    "        plt.title('ROC Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "        # Precision-Recall Curve subplot\n",
    "        plt.subplot(1, 3, 2)\n",
    "        precision, recall, thresholds_pr = precision_recall_curve(y_test, y_proba)\n",
    "        plt.plot(recall, precision, color='blue', lw=2)\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Threshold vs F1-score\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.plot(thresholds, f1_scores, 'g-', lw=2)\n",
    "        plt.axvline(x=optimal_threshold, color='red', linestyle='--', \n",
    "                   label=f'Optimal: {optimal_threshold:.2f}')\n",
    "        plt.xlabel('Threshold')\n",
    "        plt.ylabel('F1-Score')\n",
    "        plt.title('Threshold Optimization')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                   xticklabels=[\"Legit (Pred)\", \"Attack (Pred)\"], \n",
    "                   yticklabels=[\"Legit (True)\", \"Attack (True)\"])\n",
    "        plt.title(f\"Confusion Matrix (Threshold: {optimal_threshold:.2f})\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.show()\n",
    "\n",
    "        # 14) save\n",
    "        self.model = clf\n",
    "        self.ml_feature_columns = X.columns.tolist()\n",
    "        if save_model:\n",
    "            joblib.dump({\"model\": clf, \"scaler\": self.scaler, \"features\": self.ml_feature_columns}, self.ml_model_path)\n",
    "            print(f\"‚úÖ Model + scaler saved to {self.ml_model_path}\")\n",
    "\n",
    "    # ------------------------\n",
    "    # Predict / unified scoring\n",
    "    # ------------------------\n",
    "    def load_model(self, model_path=None):\n",
    "        path = model_path if model_path else self.ml_model_path\n",
    "        if os.path.exists(path):\n",
    "            obj = joblib.load(path)\n",
    "            self.model = obj.get(\"model\", obj)\n",
    "            self.scaler = obj.get(\"scaler\", self.scaler)\n",
    "            self.ml_feature_columns = obj.get(\"features\", self.ml_feature_columns)\n",
    "            print(f\"‚úÖ Loaded model from {path}\")\n",
    "        else:\n",
    "            raise FileNotFoundError(path)\n",
    "\n",
    "    def ml_risk_for_pair(self, last_login, current_login):\n",
    "        \"\"\"Return probability of attack (0-1) from ML model for a given pair (dict-like).\"\"\"\n",
    "        if not self.model:\n",
    "            raise Exception(\"Model not trained or loaded.\")\n",
    "        \n",
    "        dummy_df = pd.DataFrame([{\n",
    "            \"time\": current_login.get(\"time\"),\n",
    "            \"User ID\": current_login.get(\"user_id\", None),\n",
    "            \"Country\": current_login.get(\"Country\", current_login.get(\"country\")),\n",
    "            \"City\": current_login.get(\"City\", current_login.get(\"city\")),\n",
    "            \"Device Type\": current_login.get(\"Device Type\", current_login.get(\"device_type\")),\n",
    "            \"Round-Trip Time [ms]\": current_login.get(\"Round-Trip Time [ms]\", current_login.get(\"rtt_ms\", None)),\n",
    "            \"Is Attack IP\": current_login.get(\"Is Attack IP\", current_login.get(\"is_attack_ip\", False)),\n",
    "            \"Login Successful\": current_login.get(\"Login Successful\", current_login.get(\"login_successful\", True)),\n",
    "            \"User Agent String\": current_login.get(\"User Agent String\", current_login.get(\"user_agent\", \"\")),\n",
    "            \"ASN\": current_login.get(\"ASN\", current_login.get(\"asn\", None)),\n",
    "            \"label\": current_login.get(\"label\", False)\n",
    "        }])\n",
    "        \n",
    "        two_rows = pd.concat([\n",
    "            pd.DataFrame([{\n",
    "                \"time\": last_login.get(\"time\"),\n",
    "                \"User ID\": last_login.get(\"user_id\", None),\n",
    "                \"Country\": last_login.get(\"Country\", last_login.get(\"country\")),\n",
    "                \"City\": last_login.get(\"City\", last_login.get(\"city\")),\n",
    "                \"Device Type\": last_login.get(\"Device Type\", last_login.get(\"device_type\")),\n",
    "                \"Round-Trip Time [ms]\": last_login.get(\"Round-Trip Time [ms]\", last_login.get(\"rtt_ms\", None)),\n",
    "                \"Is Attack IP\": last_login.get(\"Is Attack IP\", last_login.get(\"is_attack_ip\", False)),\n",
    "                \"Login Successful\": last_login.get(\"Login Successful\", last_login.get(\"login_successful\", True)),\n",
    "                \"User Agent String\": last_login.get(\"User Agent String\", last_login.get(\"user_agent\", \"\")),\n",
    "                \"ASN\": last_login.get(\"ASN\", last_login.get(\"asn\", None)),\n",
    "                \"label\": last_login.get(\"label\", False)\n",
    "            }]),\n",
    "            dummy_df\n",
    "        ], ignore_index=True)\n",
    "        X_single, _ = self.build_ml_features_for_df(two_rows)\n",
    "        if X_single.shape[0] == 0:\n",
    "            return 0.5\n",
    "        X_single = X_single.fillna(0)\n",
    "        X_scaled = self.scaler.transform(X_single)\n",
    "        proba = self.model.predict_proba(X_scaled)[:, 1][0]\n",
    "        return float(proba)\n",
    "\n",
    "    def unified_risk_score(self, user_history_df, last_login, current_login,\n",
    "                           weights={\"ml\": 0.4, \"travel\": 0.3, \"behavior\": 0.2, \"technical\": 0.1}):\n",
    "        \"\"\"\n",
    "        Compute the final unified risk score (0-1) and return breakdown + recommended action.\n",
    "        last_login/current_login: dict-like with keys matching dataset columns (time must be datetime)\n",
    "        user_history_df: DataFrame of prior logins (may be empty)\n",
    "        \"\"\"\n",
    "        # Prepare datetimes\n",
    "        last_time = pd.to_datetime(last_login.get(\"time\", last_login.get(\"Login Timestamp\", None)))\n",
    "        curr_time = pd.to_datetime(current_login.get(\"time\", current_login.get(\"Login Timestamp\", None)))\n",
    "\n",
    "        # ML risk (probability)\n",
    "        try:\n",
    "            ml_prob = self.ml_risk_for_pair(last_login, current_login)\n",
    "        except Exception:\n",
    "            ml_prob = 0.5\n",
    "\n",
    "        # Travel analysis\n",
    "        travel_info = self.travel_plausibility(last_time,\n",
    "                                              last_login.get(\"City\", last_login.get(\"city\")),\n",
    "                                              last_login.get(\"Country\", last_login.get(\"country\")),\n",
    "                                              curr_time,\n",
    "                                              current_login.get(\"City\", current_login.get(\"city\")),\n",
    "                                              current_login.get(\"Country\", current_login.get(\"country\")))\n",
    "        travel_risk = travel_info[\"travel_risk\"]\n",
    "\n",
    "        # Behavioral\n",
    "        behavior_info = self.behavioral_consistency_score(user_history_df, current_login)\n",
    "        behavior_risk = 1.0 - behavior_info[\"consistency_score\"]\n",
    "\n",
    "        # Technical\n",
    "        tech_info = self.technical_score(current_login)\n",
    "        technical_risk = tech_info[\"technical_score\"]\n",
    "\n",
    "        # Combine\n",
    "        final = (weights[\"ml\"] * ml_prob +\n",
    "                 weights[\"travel\"] * travel_risk +\n",
    "                 weights[\"behavior\"] * behavior_risk +\n",
    "                 weights[\"technical\"] * technical_risk)\n",
    "        final = max(0.0, min(1.0, final))\n",
    "\n",
    "        # Decide action\n",
    "        if final < 0.3:\n",
    "            level, action = \"LOW\", \"ALLOW\"\n",
    "        elif final < 0.6:\n",
    "            level, action = \"MEDIUM\", \"ALLOW_WITH_OTP\"\n",
    "        else:\n",
    "            # if travel impossible, prefer BLOCK\n",
    "            action = \"BLOCK\" if not travel_info[\"plausible\"] else \"STRICT_VERIFICATION\"\n",
    "            level = \"HIGH\"\n",
    "\n",
    "        return {\n",
    "            \"final_risk_score\": final,\n",
    "            \"risk_level\": level,\n",
    "            \"action\": action,\n",
    "            \"components\": {\n",
    "                \"ml_prob\": ml_prob,\n",
    "                \"travel_risk\": travel_risk,\n",
    "                \"behavior_risk\": behavior_risk,\n",
    "                \"technical_risk\": technical_risk\n",
    "            },\n",
    "            \"travel_info\": travel_info,\n",
    "            \"behavior_info\": behavior_info,\n",
    "            \"technical_info\": tech_info\n",
    "        }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration - change these paths as needed\n",
    "    dataset_path = r\"C:\\Users\\Brando\\Desktop\\School\\Project\\BantAI_Datawave\\rba-dataset.csv\"\n",
    "    model_path = \"bantai_model.pkl\"\n",
    "\n",
    "    # Initialize BantAI system\n",
    "    print(\"üöÄ Initializing BantAI TravelAware Fraud Detection System...\")\n",
    "    bantai = BantAI_TravelAware(\n",
    "        cache_file=\"geocache.json\", \n",
    "        ml_model_path=model_path, \n",
    "        geocode_delay=1.0\n",
    "    )\n",
    "\n",
    "    # Train ML component on dataset subset\n",
    "    print(\"üìö Training ML model on dataset...\")\n",
    "    # label_column can be \"Is Attack IP\" or \"Is Account Takeover\"\n",
    "    bantai.train_model_from_csv(\n",
    "        dataset_path, \n",
    "        nrows=20000,  # Use subset for faster training\n",
    "        label_column=\"Is Attack IP\", \n",
    "        use_smote=True, \n",
    "        save_model=True,\n",
    "        threshold=0.5  # This will be optimized automatically\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Training completed! Model saved and ready for fraud detection.\")\n",
    "\n",
    "\n",
    "    #20k sweet 78\n",
    "    #50k sweet 58"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
