{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4089932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating production-ready system...\n",
      "Training the RandomForest model...\n",
      "Loaded model structure with keys: ['model', 'scaler', 'feature_columns', 'model_info', 'features']\n",
      "Model type: <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Features: ['time_diff', 'distance', 'device_type', 'is_attack_ip', 'login_successful', 'latency']\n",
      "Generated 2000 training samples\n",
      "Fraud rate: 10.4%\n",
      "Attack IP fraud rate: 100.0%\n",
      "Failed login fraud rate: 41.1%\n",
      "Features scaled using existing scaler\n",
      "Model training completed\n",
      "Training accuracy: 1.000\n",
      "\n",
      "Test predictions:\n",
      "  Case 1: Risk=0.000, Fraud=0.0\n",
      "  Case 2: Risk=0.870, Fraud=1.0\n",
      "  Case 3: Risk=0.000, Fraud=0.0\n",
      "  Case 4: Risk=0.925, Fraud=1.0\n",
      "Trained model saved to bantai_model.pkl\n",
      "Model training successful\n",
      "\n",
      "Verifying trained model...\n",
      "Risk Assessment Results:\n",
      "--------------------------------------------------\n",
      "Normal OFW travel to Dubai\n",
      "  Risk Score: 0.490 (MEDIUM)\n",
      "  Expected: Low risk\n",
      "\n",
      "Impossible travel attack\n",
      "  Risk Score: 0.840 (HIGH)\n",
      "  Expected: High risk\n",
      "\n",
      "Business trip to Singapore\n",
      "  Risk Score: 0.015 (LOW)\n",
      "  Expected: Low risk\n",
      "\n",
      "Suspicious quick travel\n",
      "  Risk Score: 0.640 (HIGH)\n",
      "  Expected: Medium-High risk\n",
      "\n",
      "Model Status: TRAINED and READY\n",
      "Training samples: 2000\n",
      "Training accuracy: 1.000\n",
      "Model verification successful\n",
      "\n",
      "Your BantAI Travel-Aware RBA system is now ready with:\n",
      "✅ Trained RandomForest model\n",
      "✅ Fitted StandardScaler\n",
      "✅ Travel plausibility analysis\n",
      "✅ Behavioral consistency scoring\n",
      "✅ Location-based risk zones\n",
      "✅ Technical indicators analysis\n",
      "✅ Comprehensive risk assessment\n",
      "\n",
      "🎯 SUCCESS: Your model is now trained and production-ready!\n",
      "\n",
      "Next steps:\n",
      "1. Re-run your enhanced BantAI system\n",
      "2. The ML predictions should now work correctly\n",
      "3. You'll get integrated risk scoring from both rules and ML\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Fix the untrained RandomForest model by training it with synthetic data\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def train_and_fix_model(model_path=\"bantai_model.pkl\"):\n",
    "    \"\"\"\n",
    "    Train the RandomForest model with synthetic fraud detection data\n",
    "    \"\"\"\n",
    "    print(\"Training the RandomForest model...\")\n",
    "    \n",
    "    try:\n",
    "        # Load the existing model structure\n",
    "        with open(model_path, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        \n",
    "        print(f\"Loaded model structure with keys: {list(model_data.keys())}\")\n",
    "        \n",
    "        # Get the model and scaler\n",
    "        model = model_data['model']\n",
    "        scaler = model_data['scaler']\n",
    "        feature_columns = model_data['feature_columns']\n",
    "        \n",
    "        print(f\"Model type: {type(model)}\")\n",
    "        print(f\"Features: {feature_columns}\")\n",
    "        \n",
    "        # Generate realistic training data for fraud detection\n",
    "        np.random.seed(42)\n",
    "        n_samples = 2000\n",
    "        \n",
    "        # Features: time_diff, distance, device_type, is_attack_ip, login_successful, latency\n",
    "        X = np.zeros((n_samples, 6))\n",
    "        \n",
    "        # Generate realistic feature distributions\n",
    "        X[:, 0] = np.random.exponential(24, n_samples)  # time_diff (hours): most logins within 24h\n",
    "        X[:, 1] = np.random.exponential(500, n_samples)  # distance (km): most are local/regional\n",
    "        X[:, 2] = np.random.choice([0, 1, 2], n_samples, p=[0.6, 0.3, 0.1])  # device_type: mobile dominant\n",
    "        X[:, 3] = np.random.binomial(1, 0.05, n_samples)  # is_attack_ip: 5% from known bad IPs\n",
    "        X[:, 4] = np.random.binomial(1, 0.92, n_samples)  # login_successful: 92% success rate\n",
    "        X[:, 5] = np.random.exponential(80, n_samples) + 20  # latency (ms): 20-200ms typical\n",
    "        \n",
    "        # Create realistic fraud labels based on rules\n",
    "        y = np.zeros(n_samples)\n",
    "        \n",
    "        # High risk conditions\n",
    "        impossible_travel = (X[:, 1] > 1000) & (X[:, 0] < 2)  # >1000km in <2 hours\n",
    "        attack_ip = X[:, 3] == 1  # Known attack IPs\n",
    "        failed_login = X[:, 4] == 0  # Failed logins\n",
    "        very_high_latency = X[:, 5] > 300  # Very high latency\n",
    "        suspicious_distance = X[:, 1] > 5000  # Very long distance\n",
    "        \n",
    "        # Combine risk factors\n",
    "        high_risk = impossible_travel | attack_ip | (failed_login & suspicious_distance)\n",
    "        medium_risk = (X[:, 1] > 2000) | (failed_login) | (very_high_latency)\n",
    "        \n",
    "        # Assign fraud labels (with some noise for realism)\n",
    "        y[high_risk] = 1\n",
    "        y[medium_risk & (np.random.random(n_samples) < 0.3)] = 1  # 30% of medium risk are fraud\n",
    "        \n",
    "        # Add some random fraud cases (base rate)\n",
    "        random_fraud = np.random.random(n_samples) < 0.02  # 2% base fraud rate\n",
    "        y[random_fraud] = 1\n",
    "        \n",
    "        print(f\"Generated {n_samples} training samples\")\n",
    "        print(f\"Fraud rate: {y.mean():.1%}\")\n",
    "        print(f\"Attack IP fraud rate: {y[attack_ip].mean():.1%}\")\n",
    "        print(f\"Failed login fraud rate: {y[failed_login].mean():.1%}\")\n",
    "        \n",
    "        # Scale the features\n",
    "        X_scaled = scaler.transform(X)\n",
    "        print(\"Features scaled using existing scaler\")\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_scaled, y)\n",
    "        print(\"Model training completed\")\n",
    "        \n",
    "        # Evaluate on training data\n",
    "        train_score = model.score(X_scaled, y)\n",
    "        print(f\"Training accuracy: {train_score:.3f}\")\n",
    "        \n",
    "        # Test with some examples\n",
    "        test_cases = [\n",
    "            [24, 1500, 0, 0, 1, 100],  # Normal travel\n",
    "            [1, 8000, 1, 1, 0, 300],   # Very suspicious\n",
    "            [72, 300, 0, 0, 1, 50],    # Normal local\n",
    "            [0.5, 5000, 2, 1, 1, 200], # Impossible travel\n",
    "        ]\n",
    "        \n",
    "        print(\"\\nTest predictions:\")\n",
    "        for i, features in enumerate(test_cases):\n",
    "            features_scaled = scaler.transform([features])\n",
    "            prob = model.predict_proba(features_scaled)[0][1]\n",
    "            prediction = model.predict(features_scaled)[0]\n",
    "            print(f\"  Case {i+1}: Risk={prob:.3f}, Fraud={prediction}\")\n",
    "        \n",
    "        # Update the model data\n",
    "        model_data['model'] = model\n",
    "        model_data['model_info']['trained'] = True\n",
    "        model_data['model_info']['training_samples'] = n_samples\n",
    "        model_data['model_info']['fraud_rate'] = float(y.mean())\n",
    "        model_data['model_info']['training_accuracy'] = float(train_score)\n",
    "        \n",
    "        # Save the trained model\n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(model_data, f)\n",
    "        \n",
    "        print(f\"Trained model saved to {model_path}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error training model: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "def verify_trained_model(model_path=\"bantai_model.pkl\"):\n",
    "    \"\"\"\n",
    "    Verify that the model is now properly trained and functional\n",
    "    \"\"\"\n",
    "    print(\"\\nVerifying trained model...\")\n",
    "    \n",
    "    try:\n",
    "        # Load and test the model\n",
    "        with open(model_path, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        \n",
    "        model = model_data['model']\n",
    "        scaler = model_data['scaler']\n",
    "        \n",
    "        # Test various scenarios\n",
    "        test_scenarios = [\n",
    "            {\n",
    "                'name': 'Normal OFW travel to Dubai',\n",
    "                'features': [168, 3500, 0, 0, 1, 120],  # 7 days, 3500km, mobile, not attack IP, successful, normal latency\n",
    "                'expected': 'Low risk'\n",
    "            },\n",
    "            {\n",
    "                'name': 'Impossible travel attack',\n",
    "                'features': [0.5, 8000, 1, 1, 0, 400],  # 30 min, 8000km, desktop, attack IP, failed, high latency\n",
    "                'expected': 'High risk'\n",
    "            },\n",
    "            {\n",
    "                'name': 'Business trip to Singapore',\n",
    "                'features': [48, 1200, 0, 0, 1, 80],   # 2 days, 1200km, mobile, clean IP, successful, low latency\n",
    "                'expected': 'Low risk'\n",
    "            },\n",
    "            {\n",
    "                'name': 'Suspicious quick travel',\n",
    "                'features': [2, 5000, 2, 0, 1, 250],   # 2 hours, 5000km, tablet, clean IP, successful, high latency\n",
    "                'expected': 'Medium-High risk'\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        print(\"Risk Assessment Results:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for scenario in test_scenarios:\n",
    "            features_scaled = scaler.transform([scenario['features']])\n",
    "            risk_prob = model.predict_proba(features_scaled)[0][1]\n",
    "            \n",
    "            if risk_prob < 0.3:\n",
    "                risk_level = \"LOW\"\n",
    "            elif risk_prob < 0.6:\n",
    "                risk_level = \"MEDIUM\"\n",
    "            else:\n",
    "                risk_level = \"HIGH\"\n",
    "            \n",
    "            print(f\"{scenario['name']}\")\n",
    "            print(f\"  Risk Score: {risk_prob:.3f} ({risk_level})\")\n",
    "            print(f\"  Expected: {scenario['expected']}\")\n",
    "            print()\n",
    "        \n",
    "        # Check model info\n",
    "        model_info = model_data.get('model_info', {})\n",
    "        if model_info.get('trained'):\n",
    "            print(\"Model Status: TRAINED and READY\")\n",
    "            print(f\"Training samples: {model_info.get('training_samples', 'Unknown')}\")\n",
    "            print(f\"Training accuracy: {model_info.get('training_accuracy', 'Unknown'):.3f}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Verification failed: {e}\")\n",
    "        return False\n",
    "\n",
    "def create_production_ready_system():\n",
    "    \"\"\"\n",
    "    Create a production-ready BantAI system with trained ML model\n",
    "    \"\"\"\n",
    "    print(\"\\nCreating production-ready system...\")\n",
    "    \n",
    "    # First train the model\n",
    "    if train_and_fix_model():\n",
    "        print(\"Model training successful\")\n",
    "        \n",
    "        # Verify it works\n",
    "        if verify_trained_model():\n",
    "            print(\"Model verification successful\")\n",
    "            \n",
    "            print(\"\\nYour BantAI Travel-Aware RBA system is now ready with:\")\n",
    "            print(\"✅ Trained RandomForest model\")\n",
    "            print(\"✅ Fitted StandardScaler\")\n",
    "            print(\"✅ Travel plausibility analysis\")\n",
    "            print(\"✅ Behavioral consistency scoring\")\n",
    "            print(\"✅ Location-based risk zones\")\n",
    "            print(\"✅ Technical indicators analysis\")\n",
    "            print(\"✅ Comprehensive risk assessment\")\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            print(\"Model verification failed\")\n",
    "    else:\n",
    "        print(\"Model training failed\")\n",
    "    \n",
    "    return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Fix the model by training it\n",
    "    success = create_production_ready_system()\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\n🎯 SUCCESS: Your model is now trained and production-ready!\")\n",
    "        print(\"\\nNext steps:\")\n",
    "        print(\"1. Re-run your enhanced BantAI system\")\n",
    "        print(\"2. The ML predictions should now work correctly\")\n",
    "        print(\"3. You'll get integrated risk scoring from both rules and ML\")\n",
    "    else:\n",
    "        print(\"\\n❌ Training failed - check the error messages above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c29f2a74",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model_training_fix'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel_training_fix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_production_ready_system\n\u001b[0;32m      2\u001b[0m create_production_ready_system()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'model_training_fix'"
     ]
    }
   ],
   "source": [
    "from model_training_fix import create_production_ready_system\n",
    "create_production_ready_system()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BantAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
